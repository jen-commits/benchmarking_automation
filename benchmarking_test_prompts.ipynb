{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "database_llm_switch() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 148\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_relevence:\n\u001b[1;32m    147\u001b[0m     rel_prompt, rel_parser \u001b[38;5;241m=\u001b[39m create_prompt(relevance_prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     store_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatabase_llm_switch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_parser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestcases_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     rel_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(store_data, columns\u001b[38;5;241m=\u001b[39mrelevance_answer_headers)\n\u001b[1;32m    150\u001b[0m     display(rel_df)\n",
      "\u001b[0;31mTypeError\u001b[0m: database_llm_switch() takes 1 positional argument but 4 were given"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "#os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_criteria_from_file(parser, testcases_df, eval_llm, prompt):\n",
    "    eval_store_data = []\n",
    "    \n",
    "    #Iterate over test cases and evaluate answers from file\n",
    "    for index, row in testcases_df.iterrows():\n",
    "        question = row[\"question\"]\n",
    "        reference = row[\"reference\"]\n",
    "        answer = row[\"nps_advisor_answer\"]\n",
    "        \n",
    "        # Evaluate response\n",
    "        eval_prompt_and_model = prompt | eval_llm\n",
    "        output = eval_prompt_and_model.invoke({\"question\": question, \"answer\": answer, \"reference\": reference})\n",
    "\n",
    "        # Parse the output using the parser\n",
    "        parsed_result = parser.invoke(output)\n",
    "\n",
    "        # Store results\n",
    "        eval_store_data.append(parsed_result)\n",
    "        eval_store_data[index][\"question\"] = question\n",
    "        eval_store_data[index][\"reference\"] = reference\n",
    "        eval_store_data[index][\"answer\"] = answer  \n",
    "    return eval_store_data\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_llm_output(parser, testcases_df, eval_llm, tested_llm, prompt):\n",
    "    eval_store_data = []\n",
    "    \n",
    "    #Iterate over test cases and call LLM(s) for answer\n",
    "    for index, row in testcases_df.iterrows():\n",
    "        question = row[\"question\"]\n",
    "        reference = row[\"reference\"]\n",
    "\n",
    "        # # Get answer from LLM\n",
    "        answer = tested_llm.invoke([HumanMessage(content=question)]).content\n",
    "        \n",
    "        # Evaluate response\n",
    "        eval_prompt_and_model = prompt | eval_llm\n",
    "        output = eval_prompt_and_model.invoke({\"question\": question, \"answer\": answer, \"reference\": reference})\n",
    "\n",
    "        # Parse the output using the parser\n",
    "        parsed_result = parser.invoke(output)\n",
    "\n",
    "        # Store results\n",
    "        eval_store_data.append(parsed_result)\n",
    "        eval_store_data[index][\"question\"] = question\n",
    "        eval_store_data[index][\"reference\"] = reference\n",
    "        eval_store_data[index][\"answer\"] = answer  \n",
    "    return eval_store_data\n",
    "\n",
    "# Create a prompt \n",
    "def create_prompt(prompt_template, criteria):\n",
    "    # Define output schema\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"evaluation\", description=\"feedback on answer\"),\n",
    "        ResponseSchema(\n",
    "            name=criteria,\n",
    "            description=\"evaluation of answer, must be a percentage\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Define pydanthic output parser\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    \n",
    "    eval_prompt = PromptTemplate(\n",
    "        template = prompt_template.template,\n",
    "        input_variables=[\"question\", \"answer\", \"reference\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "    )\n",
    "    return eval_prompt, output_parser\n",
    "\n",
    "def execute_benchmarks(prompt, criteria, headers):\n",
    "    prompt, parser = create_prompt(prompt, criteria)\n",
    "    if criteria == \"prioritization\": # Select only rows with prioritization flag\n",
    "        testcases_df = testcases_df.loc[testcases_df['prioritization_flag'] == 1]\n",
    "        \n",
    "    store_data = evaluate_criteria_from_file(parser, testcases_df, eval_model, prompt)\n",
    "    df = pd.DataFrame(store_data, columns=headers)\n",
    "    return df\n",
    "\n",
    "def calculate_delta(reference_data, criteria, criteria_header, dataframe):\n",
    "    reference_data = reference_data.loc[:,[\"question\", \"reference\", criteria_header]]\n",
    "    output_df = pd.merge(dataframe, reference_data, how=\"inner\", on=[\"question\", \"reference\"])\n",
    "    output_df[criteria] = output_df[criteria].str.rstrip('%').astype('float')/100.0\n",
    "    output_df[criteria_header] = output_df[criteria_header].str.rstrip('%').astype('float')/100.0\n",
    "    output_df['delta'] = output_df.apply(lambda x: abs(x[criteria] - x[criteria_header]), axis=1)\n",
    "    return output_df\n",
    "\n",
    "def database_llm_switch(switch):\n",
    "    if switch == 'llm':\n",
    "        return evaluate_llm_output\n",
    "    if switch == 'database':\n",
    "        return evaluate_criteria_from_file \n",
    "    \n",
    "# Load test cases and data store\n",
    "testcases_df = pd.read_csv(\"testcases_v1.csv\")\n",
    "manual_scores_df = pd.read_csv(\"reference_scoring_v1.csv\")\n",
    "\n",
    "# Define variables\n",
    "relevance_answer_headers = [\"question\", \"reference\", \"answer\", \"evaluation\", \"relevance\"]\n",
    "depth_answer_headers = [\"question\", \"reference\", \"answer\", \"evaluation\", \"depth\"]\n",
    "priority_answer_headers = [\"question\", \"reference\", \"answer\", \"evaluation\", \"prioritization\"]\n",
    "\n",
    "# Pull latest prompt from LangSmith\n",
    "relevance_prompt = hub.pull(\"benchmarking_relevance_v1\")\n",
    "depth_prompt = hub.pull(\"benchmarking_depth_v1\")\n",
    "priority_prompt = hub.pull(\"benchmarking_prioritization_v1\")\n",
    "\n",
    "# Initialize models to test\n",
    "gpt4_model  = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "gemini_model = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# Initialize evaluator model\n",
    "eval_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "test_relevence = True\n",
    "test_depth = False\n",
    "test_priority = False\n",
    "\n",
    "# Run relevance benchmark\n",
    "\n",
    "\n",
    "if test_relevence:\n",
    "    rel_prompt, rel_parser = create_prompt(relevance_prompt, \"relevance\")\n",
    "    store_data = evaluate_criteria_from_file(rel_parser, testcases_df, eval_model, rel_prompt)\n",
    "    rel_df = pd.DataFrame(store_data, columns=relevance_answer_headers)\n",
    "    display(rel_df)\n",
    "    \n",
    "    # Calculate delta\n",
    "    criteria_header = \"nps_advisor_relevance\"\n",
    "    criteria = \"relevance\" \n",
    "    rel_delta_df = calculate_delta(manual_scores_df, criteria, criteria_header, rel_df)\n",
    "    %store rel_delta_df\n",
    "    \n",
    "    # Output\n",
    "    print(\"Relevance Delta: \"+str(rel_delta_df['delta'].mean()))\n",
    "    rel_delta_df.to_excel(\"rel_scoring.xlsx\")\n",
    "\n",
    "# Run depth benchmark\n",
    "if test_depth:\n",
    "    dep_prompt, dep_parser = create_prompt(depth_prompt, \"depth\")\n",
    "    store_data = evaluate_criteria_from_file(dep_parser, testcases_df, eval_model, dep_prompt)\n",
    "    dep_df = pd.DataFrame(store_data, columns=depth_answer_headers)\n",
    "    display(dep_df)\n",
    "    \n",
    "    # Calculate delta\n",
    "    criteria_header = \"nps_advisor_depth\"\n",
    "    criteria = \"depth\" \n",
    "    dep_delta_df = calculate_delta(manual_scores_df, criteria, criteria_header, dep_df)\n",
    "    %store dep_delta_df\n",
    "\n",
    "    # Output\n",
    "    print(\"Depth Delta: \"+str(dep_delta_df['delta'].mean()))\n",
    "    dep_delta_df.to_excel(\"dep_scoring.xlsx\")\n",
    "    \n",
    "# Run priority benchmark\n",
    "if test_priority:\n",
    "    prompt, parser = create_prompt(priority_prompt, \"prioritization\")\n",
    "    testcases_df = testcases_df.loc[testcases_df['prioritization_flag'] == 1] # Select only rows with prioritization flag\n",
    "    store_data = evaluate_criteria_from_file(parser, testcases_df, eval_model, prompt)\n",
    "    pri_df = pd.DataFrame(store_data, columns=priority_answer_headers)\n",
    "    display(pri_df)\n",
    "    \n",
    "\n",
    "    # Calculate delta\n",
    "    criteria_header = \"nps_advisor_priority\"\n",
    "    criteria = \"prioritization\" \n",
    "    pri_delta_df = calculate_delta(manual_scores_df, criteria, criteria_header, pri_df)\n",
    "    %store pri_delta_df\n",
    "\n",
    "    # Output\n",
    "    print(\"Prioritization Delta: \"+str(pri_delta_df['delta'].mean()))\n",
    "    pri_delta_df.to_excel(\"pri_scoring.xlsx\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer</th>\n",
       "      <th>evaluation_x</th>\n",
       "      <th>relevance</th>\n",
       "      <th>nps_advisor_relevance</th>\n",
       "      <th>delta_x</th>\n",
       "      <th>evaluation_y</th>\n",
       "      <th>depth</th>\n",
       "      <th>nps_advisor_depth</th>\n",
       "      <th>delta_y</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>prioritization</th>\n",
       "      <th>nps_advisor_priority</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nWhat are the top issues causing detractors f...</td>\n",
       "      <td>Network Coverage and Reliability: Customers ha...</td>\n",
       "      <td>Detractors of Circles.Life have expressed diss...</td>\n",
       "      <td>The answer addresses some of the issues mentio...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>The answer covers several issues and solutions...</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>The answer identifies three main issues: rewar...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At which stages do customers encounter either ...</td>\n",
       "      <td>Onboarding:\\nDelight: Promoters in the data of...</td>\n",
       "      <td>Customers encounter friction or delight at var...</td>\n",
       "      <td>The answer effectively covers the key points m...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer effectively covers the key subpoint...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the reasons for NPS, which aspects sh...</td>\n",
       "      <td>Positive Aspects (Promoter Reasons):\\nValue fo...</td>\n",
       "      <td>To improve the Net Promoter Score (NPS) for Ci...</td>\n",
       "      <td>The answer covers several key aspects that ali...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a comprehensive list of as...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compare the NPS of Circles with other Singapor...</td>\n",
       "      <td>Circles.Life has achieved a Net Promoter Score...</td>\n",
       "      <td>As of September 2024, Circles.Life Singapore h...</td>\n",
       "      <td>The answer provides a detailed comparison of C...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>The answer provides a good overview of the fac...</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.2468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do certain customer segments experience signif...</td>\n",
       "      <td>Segment-Specific NPS Outcomes\\nPlan Type:\\n\\nH...</td>\n",
       "      <td>Yes, certain customer segments do experience s...</td>\n",
       "      <td>The answer identifies that certain customer se...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>The answer provides a comprehensive overview o...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do NPS scores vary across customer segment...</td>\n",
       "      <td>1. Geography (Roaming vs. Non-Roaming Segments...</td>\n",
       "      <td>NPS scores for Circles.Life vary significantly...</td>\n",
       "      <td>The answer provides a detailed analysis of NPS...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>The answer provides a detailed analysis of NPS...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many customers are passive in Circles.Life...</td>\n",
       "      <td>Circles.Life has approximately 1,478 passive c...</td>\n",
       "      <td>The current number of passive customers for Ci...</td>\n",
       "      <td>The answer provides a detailed explanation of ...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>The answer provides a detailed breakdown of pa...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a detailed analysis of the...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is there a difference in NPS score between por...</td>\n",
       "      <td>The average NPS score for New Number customers...</td>\n",
       "      <td>Yes, there is a difference in NPS scores betwe...</td>\n",
       "      <td>The answer provides a detailed analysis of the...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a detailed analysis of the...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the NPS for this year (2024) for Cir...</td>\n",
       "      <td>Average NPS of -17 in 2024. \\n\\nJanuary 2024: ...</td>\n",
       "      <td>As of 2024, Circles.Life has experienced fluct...</td>\n",
       "      <td>The answer provides a detailed month-by-month ...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>The answer provides a detailed month-by-month ...</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>The answer provides a detailed month-by-month ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the primary reasons for promoters' hi...</td>\n",
       "      <td>Value for Money: Affordable plans that provide...</td>\n",
       "      <td>Promoters of Circles.Life have provided severa...</td>\n",
       "      <td>The answer covers several key points related t...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>The answer provides several reasons for promot...</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are the top issues mentioned in the App S...</td>\n",
       "      <td>Network Reliability: A significant number of u...</td>\n",
       "      <td>Based on the reviews from the App Store and Go...</td>\n",
       "      <td>The answer covers several key issues mentioned...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>The answer provides a comprehensive overview o...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>The answer provides a comprehensive list of is...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What emerging themes or trends for Circles.Lif...</td>\n",
       "      <td>\"Analyzing the provided NPS data and customer ...</td>\n",
       "      <td>Emerging themes and trends in customer feedbac...</td>\n",
       "      <td>The answer captures several key points from th...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>The answer covers 4 out of the 6 subpoints fro...</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>The answer identifies several key themes and t...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What key drivers contribute to customers' loya...</td>\n",
       "      <td>4 Key Strategies:\\n\\nExceptional Customer Serv...</td>\n",
       "      <td>Customers' loyalty and advocacy for Circles.Li...</td>\n",
       "      <td>The answer covers several key drivers of custo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>The answer provides a comprehensive overview o...</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What trends can be identified in NPS related t...</td>\n",
       "      <td>No data for product launches.\\nNo data for pro...</td>\n",
       "      <td>In analyzing the trends related to Net Promote...</td>\n",
       "      <td>The answer provides a detailed analysis of NPS...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a detailed analysis of NPS...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What trends have Circles life observed in NPS ...</td>\n",
       "      <td>\"2017: +54 \\n2018: +50\\n2019: +45\\n2020: +40\\n...</td>\n",
       "      <td>### Circles.Life NPS Trends Over the Past 5 Ye...</td>\n",
       "      <td>The answer provides a detailed narrative of po...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a detailed narrative of po...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The answer provides a detailed narrative of th...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   \\nWhat are the top issues causing detractors f...   \n",
       "1   At which stages do customers encounter either ...   \n",
       "2   Based on the reasons for NPS, which aspects sh...   \n",
       "3   Compare the NPS of Circles with other Singapor...   \n",
       "4   Do certain customer segments experience signif...   \n",
       "5   How do NPS scores vary across customer segment...   \n",
       "6   How many customers are passive in Circles.Life...   \n",
       "7   Is there a difference in NPS score between por...   \n",
       "8   Summarize the NPS for this year (2024) for Cir...   \n",
       "9   What are the primary reasons for promoters' hi...   \n",
       "10  What are the top issues mentioned in the App S...   \n",
       "11  What emerging themes or trends for Circles.Lif...   \n",
       "12  What key drivers contribute to customers' loya...   \n",
       "13  What trends can be identified in NPS related t...   \n",
       "14  What trends have Circles life observed in NPS ...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Network Coverage and Reliability: Customers ha...   \n",
       "1   Onboarding:\\nDelight: Promoters in the data of...   \n",
       "2   Positive Aspects (Promoter Reasons):\\nValue fo...   \n",
       "3   Circles.Life has achieved a Net Promoter Score...   \n",
       "4   Segment-Specific NPS Outcomes\\nPlan Type:\\n\\nH...   \n",
       "5   1. Geography (Roaming vs. Non-Roaming Segments...   \n",
       "6   Circles.Life has approximately 1,478 passive c...   \n",
       "7   The average NPS score for New Number customers...   \n",
       "8   Average NPS of -17 in 2024. \\n\\nJanuary 2024: ...   \n",
       "9   Value for Money: Affordable plans that provide...   \n",
       "10  Network Reliability: A significant number of u...   \n",
       "11  \"Analyzing the provided NPS data and customer ...   \n",
       "12  4 Key Strategies:\\n\\nExceptional Customer Serv...   \n",
       "13  No data for product launches.\\nNo data for pro...   \n",
       "14  \"2017: +54 \\n2018: +50\\n2019: +45\\n2020: +40\\n...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   Detractors of Circles.Life have expressed diss...   \n",
       "1   Customers encounter friction or delight at var...   \n",
       "2   To improve the Net Promoter Score (NPS) for Ci...   \n",
       "3   As of September 2024, Circles.Life Singapore h...   \n",
       "4   Yes, certain customer segments do experience s...   \n",
       "5   NPS scores for Circles.Life vary significantly...   \n",
       "6   The current number of passive customers for Ci...   \n",
       "7   Yes, there is a difference in NPS scores betwe...   \n",
       "8   As of 2024, Circles.Life has experienced fluct...   \n",
       "9   Promoters of Circles.Life have provided severa...   \n",
       "10  Based on the reviews from the App Store and Go...   \n",
       "11  Emerging themes and trends in customer feedbac...   \n",
       "12  Customers' loyalty and advocacy for Circles.Li...   \n",
       "13  In analyzing the trends related to Net Promote...   \n",
       "14  ### Circles.Life NPS Trends Over the Past 5 Ye...   \n",
       "\n",
       "                                         evaluation_x  relevance  \\\n",
       "0   The answer addresses some of the issues mentio...       0.40   \n",
       "1   The answer effectively covers the key points m...       1.00   \n",
       "2   The answer covers several key aspects that ali...       0.50   \n",
       "3   The answer provides a detailed comparison of C...       0.71   \n",
       "4   The answer identifies that certain customer se...       0.50   \n",
       "5   The answer provides a detailed analysis of NPS...       0.25   \n",
       "6   The answer provides a detailed explanation of ...       0.20   \n",
       "7   The answer provides a detailed analysis of the...       0.50   \n",
       "8   The answer provides a detailed month-by-month ...       0.90   \n",
       "9   The answer covers several key points related t...       0.33   \n",
       "10  The answer covers several key issues mentioned...       0.50   \n",
       "11  The answer captures several key points from th...       0.80   \n",
       "12  The answer covers several key drivers of custo...       0.75   \n",
       "13  The answer provides a detailed analysis of NPS...       0.50   \n",
       "14  The answer provides a detailed narrative of po...       0.00   \n",
       "\n",
       "    nps_advisor_relevance  delta_x  \\\n",
       "0                  0.6000   0.2000   \n",
       "1                  1.0000   0.0000   \n",
       "2                  0.5000   0.0000   \n",
       "3                  0.6667   0.0433   \n",
       "4                  0.6000   0.1000   \n",
       "5                  0.6250   0.3750   \n",
       "6                  0.4000   0.2000   \n",
       "7                  0.5000   0.0000   \n",
       "8                  1.0000   0.1000   \n",
       "9                  0.3333   0.0033   \n",
       "10                 0.8333   0.3333   \n",
       "11                 0.6667   0.1333   \n",
       "12                 0.5000   0.2500   \n",
       "13                 0.5000   0.0000   \n",
       "14                 0.0000   0.0000   \n",
       "\n",
       "                                         evaluation_y   depth  \\\n",
       "0   The answer covers several issues and solutions...  0.4000   \n",
       "1   The answer effectively covers the key subpoint...  0.9000   \n",
       "2   The answer provides a comprehensive list of as...  0.5000   \n",
       "3   The answer provides a good overview of the fac...  0.5714   \n",
       "4   The answer provides a comprehensive overview o...  0.5000   \n",
       "5   The answer provides a detailed analysis of NPS...  0.5000   \n",
       "6   The answer provides a detailed breakdown of pa...  0.2500   \n",
       "7   The answer provides a detailed analysis of the...  0.5000   \n",
       "8   The answer provides a detailed month-by-month ...  0.7000   \n",
       "9   The answer provides several reasons for promot...  0.2200   \n",
       "10  The answer provides a comprehensive overview o...  0.6667   \n",
       "11  The answer covers 4 out of the 6 subpoints fro...  0.6700   \n",
       "12  The answer provides a comprehensive overview o...  0.6000   \n",
       "13  The answer provides a detailed analysis of NPS...  0.5000   \n",
       "14  The answer provides a detailed narrative of po...  0.2000   \n",
       "\n",
       "    nps_advisor_depth  delta_y  \\\n",
       "0              0.6250   0.2250   \n",
       "1              0.7273   0.1727   \n",
       "2              0.4667   0.0333   \n",
       "3              0.8182   0.2468   \n",
       "4              0.5455   0.0455   \n",
       "5              0.5556   0.0556   \n",
       "6              0.2500   0.0000   \n",
       "7              0.5000   0.0000   \n",
       "8              0.4286   0.2714   \n",
       "9              0.3636   0.1436   \n",
       "10             0.7778   0.1111   \n",
       "11             0.6250   0.0450   \n",
       "12             0.7500   0.1500   \n",
       "13             0.7143   0.2143   \n",
       "14             0.2000   0.0000   \n",
       "\n",
       "                                           evaluation  prioritization  \\\n",
       "0   The answer identifies three main issues: rewar...            0.40   \n",
       "1                                                 NaN             NaN   \n",
       "2                                                 NaN             NaN   \n",
       "3                                                 NaN             NaN   \n",
       "4                                                 NaN             NaN   \n",
       "5                                                 NaN             NaN   \n",
       "6   The answer provides a detailed analysis of the...            0.40   \n",
       "7                                                 NaN             NaN   \n",
       "8   The answer provides a detailed month-by-month ...            1.00   \n",
       "9                                                 NaN             NaN   \n",
       "10  The answer provides a comprehensive list of is...            0.57   \n",
       "11  The answer identifies several key themes and t...            0.60   \n",
       "12                                                NaN             NaN   \n",
       "13                                                NaN             NaN   \n",
       "14  The answer provides a detailed narrative of th...            0.40   \n",
       "\n",
       "    nps_advisor_priority  delta  \n",
       "0                    0.2   0.20  \n",
       "1                    NaN    NaN  \n",
       "2                    NaN    NaN  \n",
       "3                    NaN    NaN  \n",
       "4                    NaN    NaN  \n",
       "5                    NaN    NaN  \n",
       "6                    0.5   0.10  \n",
       "7                    NaN    NaN  \n",
       "8                    1.0   0.00  \n",
       "9                    NaN    NaN  \n",
       "10                   0.6   0.03  \n",
       "11                   0.5   0.10  \n",
       "12                   NaN    NaN  \n",
       "13                   NaN    NaN  \n",
       "14                   0.5   0.10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def calculate_score(relevance, depth, prioritization):\n",
    "    if math.isnan(prioritization):\n",
    "        return relevance * 0.500 + depth * 0.500\n",
    "    return  relevance * 0.450 + depth * 0.450 + prioritization * 0.100\n",
    "\n",
    "def apply_calculate_score(dataframe):\n",
    "    return calculate_score(dataframe['relevance'], dataframe['depth'], dataframe['prioritization'])\n",
    "\n",
    "output_df = pd.merge(rel_delta_df, dep_delta_df, how=\"inner\", on=[\"question\", \"reference\", \"answer\"])\n",
    "output_df = pd.merge(output_df, pri_delta_df, how=\"outer\", on=[\"question\", \"reference\", \"answer\"])\n",
    "\n",
    "display(output_df)\n",
    "output_df[\"score\"] = output_df.apply(apply_calculate_score, axis=1)\n",
    "output_df.to_excel(\"weighted_score.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What+is+Circles+NPS+this+month\n",
      "['As of November 2024, Circles.Life has an NPS (Net Promoter Score) of '\n",
      " '-12.99%. This score is derived from the following breakdown of customer '\n",
      " 'responses:\\n'\n",
      " '\\n'\n",
      " '- **Detractors**: 48.31%\\n'\n",
      " '- **Passives**: 16.36%\\n'\n",
      " '- **Promoters**: 35.32%\\n'\n",
      " '\\n'\n",
      " 'The NPS score is calculated by subtracting the percentage of detractors from '\n",
      " 'the percentage of promoters. A negative NPS indicates that there are more '\n",
      " 'detractors than promoters among the customer base.']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "question = 'What is Circles NPS this month'\n",
    "url = 'https://agenticworkflows.onrender.com/run/'\n",
    "\n",
    "payload = urllib.parse.quote_plus(question)\n",
    "print(payload)\n",
    "\n",
    "response = requests.get(url + payload)\n",
    "pp.pprint(json.loads(response.content)[\"response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As of November 2024, Circles.Life has an NPS (Net Promoter Score) of -24.43%. This score reflects the percentage of detractors, passives, and promoters among its customers, indicating a challenging customer satisfaction landscape. \\n\\nHereâ€™s a breakdown of the NPS components for November 2024:\\n- **Detractor Percentage**: 52.98%\\n- **Passive Percentage**: 18.47%\\n- **Promoter Percentage**: 28.55%\\n\\nThe NPS score is calculated by subtracting the percentage of detractors from the percentage of promoters. In this case, the negative score suggests that there are more detractors than promoters, which can be a focus area for improvement in customer experience.']\n"
     ]
    }
   ],
   "source": [
    "print(json.loads(response.content)[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
